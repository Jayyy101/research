{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_subscribers</th>\n",
       "      <th>channel_videos</th>\n",
       "      <th>channel_views</th>\n",
       "      <th>video_comments</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_likes</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_views</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC7t6FZ5U17ruEXRH1WRxcTQ</td>\n",
       "      <td>Top List</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>143713154</td>\n",
       "      <td>131.0</td>\n",
       "      <td>hDcWfBq5bxM</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>10 Amazing Places That Disappear During High Tide</td>\n",
       "      <td>360859.0</td>\n",
       "      <td>10 amazing places that disappear during high t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCa2fBMGQn5Q8hiZ4MX93Tmg</td>\n",
       "      <td>Top 10 Things</td>\n",
       "      <td>424187</td>\n",
       "      <td>345</td>\n",
       "      <td>81296257</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BtHDTsAA3uI</td>\n",
       "      <td>273.0</td>\n",
       "      <td>10 Riddles That Will Trick Your Brain</td>\n",
       "      <td>23835.0</td>\n",
       "      <td>feel like you have more common sense than othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCQ-hpFPF4nOKoKPEAZM_THw</td>\n",
       "      <td>TopTenz</td>\n",
       "      <td>1113188</td>\n",
       "      <td>1437</td>\n",
       "      <td>306666947</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>pqe4AHTpzPg</td>\n",
       "      <td>3607.0</td>\n",
       "      <td>Top 10 Worst Moments in DC Comics — TopTenzNet</td>\n",
       "      <td>514051.0</td>\n",
       "      <td>Top 10 Worst Moments in DC Comics 10. Superman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCBINYCmwE29fBXCpUI8DgTA</td>\n",
       "      <td>MostAmazingTop10</td>\n",
       "      <td>4129592</td>\n",
       "      <td>2065</td>\n",
       "      <td>1243277026</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>nEGTPVWnwyo</td>\n",
       "      <td>7638.0</td>\n",
       "      <td>Top 10 Scary American Urban Legends - Part 3</td>\n",
       "      <td>334602.0</td>\n",
       "      <td>Starting off at  number 10 we have The Skunk A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCX--mGSg0UwDjl7MDL8H5Jg</td>\n",
       "      <td>BabbleTop</td>\n",
       "      <td>119764</td>\n",
       "      <td>248</td>\n",
       "      <td>53525150</td>\n",
       "      <td>549.0</td>\n",
       "      <td>T9O6rfENh7I</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>Top 10 Things Subway DOESN'T Want You To KNOW!</td>\n",
       "      <td>129069.0</td>\n",
       "      <td>About ten years ago there was no better bet\\nt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id      channel_name  channel_subscribers  \\\n",
       "0  UC7t6FZ5U17ruEXRH1WRxcTQ          Top List                    0   \n",
       "1  UCa2fBMGQn5Q8hiZ4MX93Tmg     Top 10 Things               424187   \n",
       "2  UCQ-hpFPF4nOKoKPEAZM_THw           TopTenz              1113188   \n",
       "3  UCBINYCmwE29fBXCpUI8DgTA  MostAmazingTop10              4129592   \n",
       "4  UCX--mGSg0UwDjl7MDL8H5Jg         BabbleTop               119764   \n",
       "\n",
       "   channel_videos  channel_views  video_comments     video_id  video_likes  \\\n",
       "0             193      143713154           131.0  hDcWfBq5bxM       1424.0   \n",
       "1             345       81296257            62.0  BtHDTsAA3uI        273.0   \n",
       "2            1437      306666947          1158.0  pqe4AHTpzPg       3607.0   \n",
       "3            2065     1243277026          2835.0  nEGTPVWnwyo       7638.0   \n",
       "4             248       53525150           549.0  T9O6rfENh7I       1145.0   \n",
       "\n",
       "                                         video_title  video_views  \\\n",
       "0  10 Amazing Places That Disappear During High Tide     360859.0   \n",
       "1              10 Riddles That Will Trick Your Brain      23835.0   \n",
       "2     Top 10 Worst Moments in DC Comics — TopTenzNet     514051.0   \n",
       "3       Top 10 Scary American Urban Legends - Part 3     334602.0   \n",
       "4     Top 10 Things Subway DOESN'T Want You To KNOW!     129069.0   \n",
       "\n",
       "                                          transcript  \n",
       "0  10 amazing places that disappear during high t...  \n",
       "1  feel like you have more common sense than othe...  \n",
       "2  Top 10 Worst Moments in DC Comics 10. Superman...  \n",
       "3  Starting off at  number 10 we have The Skunk A...  \n",
       "4  About ten years ago there was no better bet\\nt...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Open and read the JSON file line by line\n",
    "with open('clickbait_with_transcripts.json', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Try loading the lines to see if it works\n",
    "try:\n",
    "    # Try to load the JSON data\n",
    "    data = [json.loads(line.strip()) for line in lines]\n",
    "    # Convert the list of JSON objects into a dataframe\n",
    "    df1 = pd.json_normalize(data)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error reading JSON: {e}\")\n",
    "\n",
    "df1 = df1.drop(\"video_dislikes\", axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_subscribers</th>\n",
       "      <th>channel_videos</th>\n",
       "      <th>channel_views</th>\n",
       "      <th>video_comments</th>\n",
       "      <th>video_likes</th>\n",
       "      <th>video_views</th>\n",
       "      <th>video_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hxwpkM5w3Cc</td>\n",
       "      <td>- I tied up an FBI agent.\\n(words pop) If he s...</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>377000000</td>\n",
       "      <td>24</td>\n",
       "      <td>76059412657</td>\n",
       "      <td>94218</td>\n",
       "      <td>4751551</td>\n",
       "      <td>240148567</td>\n",
       "      <td>I Got Hunted By The FBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81mXAkFEkMs</td>\n",
       "      <td>hey what's happening y'all welcome back to ano...</td>\n",
       "      <td>UCwNEx3HyQ_wiCL9LNn3mTSw</td>\n",
       "      <td>Real Bizarre</td>\n",
       "      <td>654000</td>\n",
       "      <td>24</td>\n",
       "      <td>206980120</td>\n",
       "      <td>917</td>\n",
       "      <td>15166</td>\n",
       "      <td>6905437</td>\n",
       "      <td>10 Real Life Giants You Won’t Believe Exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9NQQKNAwaPk</td>\n",
       "      <td>I used to taste your daddy who doesn't love a ...</td>\n",
       "      <td>UCmvqviNx70U0l4ZcvUAXxhA</td>\n",
       "      <td>Top 5 Best</td>\n",
       "      <td>5480000</td>\n",
       "      <td>24</td>\n",
       "      <td>836448242</td>\n",
       "      <td>2458</td>\n",
       "      <td>56901</td>\n",
       "      <td>2776197</td>\n",
       "      <td>10 Mythical CREATURES That Actually Existed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y_PQrPRolvM</td>\n",
       "      <td>Hi!\\nWho said that giants are imaginary and on...</td>\n",
       "      <td>UCwNEx3HyQ_wiCL9LNn3mTSw</td>\n",
       "      <td>Real Bizarre</td>\n",
       "      <td>654000</td>\n",
       "      <td>24</td>\n",
       "      <td>206980120</td>\n",
       "      <td>660</td>\n",
       "      <td>9680</td>\n",
       "      <td>1294977</td>\n",
       "      <td>Real Giants Caught On Camera!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZZtYAOpHVYk</td>\n",
       "      <td>[Music] hey guys what's up it's charlie here a...</td>\n",
       "      <td>UCRyIP2oznv4UPAl1jmKS5kA</td>\n",
       "      <td>Top 10s</td>\n",
       "      <td>5130000</td>\n",
       "      <td>24</td>\n",
       "      <td>1641526994</td>\n",
       "      <td>3677</td>\n",
       "      <td>63330</td>\n",
       "      <td>9247828</td>\n",
       "      <td>10 Real Life Giants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript  \\\n",
       "0  hxwpkM5w3Cc  - I tied up an FBI agent.\\n(words pop) If he s...   \n",
       "1  81mXAkFEkMs  hey what's happening y'all welcome back to ano...   \n",
       "2  9NQQKNAwaPk  I used to taste your daddy who doesn't love a ...   \n",
       "3  Y_PQrPRolvM  Hi!\\nWho said that giants are imaginary and on...   \n",
       "4  ZZtYAOpHVYk  [Music] hey guys what's up it's charlie here a...   \n",
       "\n",
       "                 channel_id  channel_name channel_subscribers  channel_videos  \\\n",
       "0  UCX6OQ3DkcsbYNE6H8uQQuVA       MrBeast           377000000              24   \n",
       "1  UCwNEx3HyQ_wiCL9LNn3mTSw  Real Bizarre              654000              24   \n",
       "2  UCmvqviNx70U0l4ZcvUAXxhA    Top 5 Best             5480000              24   \n",
       "3  UCwNEx3HyQ_wiCL9LNn3mTSw  Real Bizarre              654000              24   \n",
       "4  UCRyIP2oznv4UPAl1jmKS5kA       Top 10s             5130000              24   \n",
       "\n",
       "  channel_views video_comments video_likes video_views  \\\n",
       "0   76059412657          94218     4751551   240148567   \n",
       "1     206980120            917       15166     6905437   \n",
       "2     836448242           2458       56901     2776197   \n",
       "3     206980120            660        9680     1294977   \n",
       "4    1641526994           3677       63330     9247828   \n",
       "\n",
       "                                   video_title  \n",
       "0                      I Got Hunted By The FBI  \n",
       "1  10 Real Life Giants You Won’t Believe Exist  \n",
       "2  10 Mythical CREATURES That Actually Existed  \n",
       "3                Real Giants Caught On Camera!  \n",
       "4                          10 Real Life Giants  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Open and read the JSON file line by line\n",
    "with open('clickbait_extra_transcripts.json', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Try loading the lines to see if it works\n",
    "try:\n",
    "    # Try to load the JSON data\n",
    "    data = [json.loads(line.strip()) for line in lines]\n",
    "    # Convert the list of JSON objects into a dataframe\n",
    "    df2 = pd.json_normalize(data)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error reading JSON: {e}\")\n",
    "df2 = df2.drop([\"Video Title\", \"Views\", \"Likes\", \"Dislikes\", \"Favorites\", \"video_dislikes\"], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_id             0\n",
       "channel_name           0\n",
       "channel_subscribers    0\n",
       "channel_videos         0\n",
       "channel_views          0\n",
       "video_comments         0\n",
       "video_id               0\n",
       "video_likes            0\n",
       "video_title            0\n",
       "video_views            0\n",
       "transcript             0\n",
       "label                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickbait_df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "\n",
    "clickbait_df[\"label\"] = pd.Series([1]*len(clickbait_df))\n",
    "clickbait_df = clickbait_df.dropna()\n",
    "clickbait_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Open and read the JSON file line by line\n",
    "with open('nonclickbait_with_transcripts.json', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Try loading the lines to see if it works\n",
    "try:\n",
    "    # Try to load the JSON data\n",
    "    data = [json.loads(line.strip()) for line in lines]\n",
    "    # Convert the list of JSON objects into a dataframe\n",
    "    nonclickbait_full_df = pd.json_normalize(data)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error reading JSON: {e}\")\n",
    "\n",
    "nonclickbait_full_df = nonclickbait_full_df.drop(\"video_dislikes\", axis=1)\n",
    "nonclickbait_full_df[\"label\"] = pd.Series([0]*len(nonclickbait_full_df))\n",
    "\n",
    "\n",
    "\n",
    "nonclickbait_balanced_df = nonclickbait_full_df.sample(n=len(clickbait_df), random_state=42)\n",
    "nonclickbait_balanced_df[\"transcript\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"10 amazing places that disappear during high tide number 10 a road in France if you're planning a trip to France make sure to be careful which roads you take they might just disappear connecting the Gulf of berf with the island of no pasage dooy is a road that is not only unique but extremely dangerous twice every day when the High Tide Rises the 2.58 M long passage disappears 13 15 ft underwater people use the road two times a day for a few hours special panels on both sides show when it's safe to travel people still get caught between the tides and there are elevated rescue towers for people to climb just in case number nine shivling Stam hesar Mahadev Temple is located in kavi kbo Gujarat India it shieling is located so close to the sea that one can only worship there during low tide the shrine is more than 150 years old and is situated near the Gulf of cambay during high tide the 4-ft Shing is completely submerged but as low tide begins we see the shivling reappear number eight M say Michael this island Castle in mon Michael France is only accessible during low tide it's claimed a Fame is that it never fell to the English during the 116 years of the Hundred Years War with tides that can vary greatly the mount can still pose dangers for visitors who avoid the causeway and attempt the Hazardous walk across the Sands from the neighboring Coast number seven Jindo and modotto these two Islands are located in the southwest of South Korea two times a year a natural Causeway opens due to extremely low tides connecting the islands for a period of 1 hour the causeway is almost 3 km long and over 40 m wide a festival is dedicated to this natural wonder and people from all over the world attend every year on each of these days visitors and tourists from each island traditionally walk to the middle of the causeway to meet one another and celebrate number six bar airport bar is a 23 squ M island off the western coast of Scotland it has an airport with three marked runways and conducts regularly scheduled flights what makes the those flights unique is that the schedule takes the tide into account during high tide the sea submerges the runways in 2011 Bara airport was voted number one in the world's top airport approaches by a poll conducted by privatefly tocom number five St Michael's Mount St Michael's Mount is a tidal Island located 366 MERS off the mounts Bay coast of Cornwall in Southwestern England it is united with the Mainland by a man-made Causeway passable only at Mid to low tide made of granite sets Legend has it that the mount was once the home of a giant named Corran who would wait ashore and steal cattle when he got hungry visitors can follow in the footsteps of Corran and visit the island during low tide when a granite Causeway appears for pedestrian Crossings inside the castle walls history lovers can enjoy a display of armor and weapons subtropical Gardens and stunning views from the castle turrets Miss low tide fairy boo services are running at high tide during the summer number four Rising tide horses four horses are standing by the Tims but you'll only see them at low tide they are located by the voxhall bridge not far from the houses of Parliament and are visible in different degrees as the water level changes created by EOS sculptor Jason decar's Taylor to encourage people to reflect on our dependence on fossil fuel the H's heads are oil well pumps also Al known as HSE head pumps two of the Riders are businessmen and two are children alluding to the people who currently control resources versus those whose Futures are at stake number three Angel Road there are tourist spots throughout Japan that are advertised as being places for couples to visit Angel Road in shodoshima Kagawa a beautiful spot where the path only appears during low tide is one of them the path is approximately 500 M long Legend has it that if couples walk this path while holding hands it leads to happiness many visit this romantic Spot movies and TV dramas are shot here as well Angel Road can be crossed about 3 hours before low tide it's the best time to visit because that's when there's the least amount of footprints number two Konan Yuan it's called a unique Paradise in the Gulf of Thailand and many who have visited the three islands of Konan Yuan seem to agree popular with divers and underwater explorers Konan Yuan islands are interconnected by a long Sandy Bridge a stunning natural phenomenon during low tide the long stripe of smooth white sand can actually be explored on foot according to thailand. at high tide the beach is submerged in crystalclear water and konang Yan regains the appearance of three islands sitting separately on the sea number one mangad white Sandbar the man OD white Sandbar completely disappears during high tide and is one of the most popular tourist destinations in negr Oriental the exceptional location can be accessed via 15-minute boat ride from the capin yahan WARF in the South Bas Bay Bay City Negros Oriental one can only witness it during low tide it is only then that the beautiful White Sands and Starfish show up but during high tide one can appreciate the beauty of the unspoiled Beach and the crystal blue ocean water so what did you think of our list what are some other amazing places that you know of that disappear during high tide let us know in the comments down below and don't forget to like And subscribe to top list for more top 10 like this one\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_videos = pd.concat([clickbait_df, nonclickbait_balanced_df], axis=0).reset_index()\n",
    "yt_videos = yt_videos.drop(\"index\", axis=1)\n",
    "yt_videos['transcript'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_videos_unbalanced = pd.concat([clickbait_df, nonclickbait_full_df], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript Only test with MLP and balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix shape: (2502, 5000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Define a function to clean the transcript text\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and any non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the transcript column\n",
    "yt_videos['clean_transcript'] = yt_videos['transcript'].apply(clean_text)\n",
    "\n",
    "# Initialize a TF-IDF vectorizer with English stop words removed\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the clean transcripts and transform the text into feature vectors\n",
    "X = tfidf_vectorizer.fit_transform(yt_videos['clean_transcript'])\n",
    "y = yt_videos['label']\n",
    "\n",
    "print(\"TF-IDF feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data splitting and model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1751, 5000)\n",
      "Test set size: (751, 5000)\n",
      "Accuracy on test set: 0.9027962716378163\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       376\n",
      "           1       0.91      0.90      0.90       375\n",
      "\n",
      "    accuracy                           0.90       751\n",
      "   macro avg       0.90      0.90      0.90       751\n",
      "weighted avg       0.90      0.90      0.90       751\n",
      "\n",
      "Confusion Matrix:\n",
      "[[342  34]\n",
      " [ 39 336]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 3: Dataset Splitting\n",
    "# Stratify ensures that both training and test sets maintain the same class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "\n",
    "# Step 4: Model Training (Random Forest)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8801597869507324\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       376\n",
      "           1       0.85      0.92      0.88       375\n",
      "\n",
      "    accuracy                           0.88       751\n",
      "   macro avg       0.88      0.88      0.88       751\n",
      "weighted avg       0.88      0.88      0.88       751\n",
      "\n",
      "Confusion Matrix:\n",
      "[[317  59]\n",
      " [ 31 344]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Step 4: Model Training using MLP\n",
    "# Configure the MLP with one hidden layer of 100 neurons, using ReLU activation and Adam optimizer\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', \n",
    "                        random_state=42, max_iter=300)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = mlp_clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9014647137150466\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       376\n",
      "           1       0.91      0.89      0.90       375\n",
      "\n",
      "    accuracy                           0.90       751\n",
      "   macro avg       0.90      0.90      0.90       751\n",
      "weighted avg       0.90      0.90      0.90       751\n",
      "\n",
      "Confusion Matrix:\n",
      "[[345  31]\n",
      " [ 43 332]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model Training: Train a logistic regression model\n",
    "logreg_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation: Predict and evaluate on the test set\n",
    "y_pred = logreg_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training with unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix shape: (8763, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply the cleaning function to the transcript column\n",
    "yt_videos_unbalanced['clean_transcript'] = yt_videos_unbalanced['transcript'].apply(clean_text)\n",
    "\n",
    "# Initialize a TF-IDF vectorizer with English stop words removed\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the clean transcripts and transform the text into feature vectors\n",
    "X = tfidf_vectorizer.fit_transform(yt_videos_unbalanced['clean_transcript'])\n",
    "y = yt_videos_unbalanced['label']\n",
    "\n",
    "print(\"TF-IDF feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (6134, 5000)\n",
      "Test set size: (2629, 5000)\n",
      "Accuracy on test set: 0.9303917839482693\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2254\n",
      "           1       0.99      0.52      0.68       375\n",
      "\n",
      "    accuracy                           0.93      2629\n",
      "   macro avg       0.96      0.76      0.82      2629\n",
      "weighted avg       0.93      0.93      0.92      2629\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2252    2]\n",
      " [ 181  194]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Dataset Splitting\n",
    "# Stratify ensures that both training and test sets maintain the same class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "\n",
    "# Step 4: Model Training (Random Forest)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9383796120197794\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2254\n",
      "           1       0.98      0.58      0.73       375\n",
      "\n",
      "    accuracy                           0.94      2629\n",
      "   macro avg       0.96      0.79      0.85      2629\n",
      "weighted avg       0.94      0.94      0.93      2629\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2250    4]\n",
      " [ 158  217]]\n"
     ]
    }
   ],
   "source": [
    "# Model Training: Train a logistic regression model\n",
    "logreg_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation: Predict and evaluate on the test set\n",
    "y_pred = logreg_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9627234689996196\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2254\n",
      "           1       0.91      0.82      0.86       375\n",
      "\n",
      "    accuracy                           0.96      2629\n",
      "   macro avg       0.94      0.90      0.92      2629\n",
      "weighted avg       0.96      0.96      0.96      2629\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2225   29]\n",
      " [  69  306]]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Training using MLP\n",
    "# Configure the MLP with one hidden layer of 100 neurons, using ReLU activation and Adam optimizer\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', \n",
    "                        random_state=42, max_iter=300)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = mlp_clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
