{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript scraping for 101 videos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/101 [00:00<00:45,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video 5WTXHdc1_zI: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/101 [00:02<02:18,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video aKkRwPGSWGQ: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/101 [00:41<01:33,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video t889ifadAMo: list index out of range\n",
      "Error fetching details for video C7QwaapFRQs: list index out of range\n",
      "Error fetching details for video hfFGTVZNjis: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/101 [00:41<00:46,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video DPCeF7ifQJU: list index out of range\n",
      "Error fetching details for video pKg8GJ7dIug: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 29/101 [00:42<00:23,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video ck1EQ-vmmc4: list index out of range\n",
      "Error fetching details for video ck1EQ-vmmc4: list index out of range\n",
      "Error fetching details for video 3-U-PUspr50: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/101 [00:42<00:13,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video bas_0jmmgI8: list index out of range\n",
      "Error fetching details for video spjY7VnFrnM: list index out of range\n",
      "Error fetching details for video oqq5aXBg3FU: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 34/101 [00:42<00:10,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video QwqiXWkKpbw: list index out of range\n",
      "Error fetching details for video XFlBwuu_p6k: list index out of range\n",
      "Error fetching details for video SJNZ1PJXxg4: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 53/101 [01:20<01:40,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video 4XnMaufLlEk: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 82/101 [02:15<00:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video ylgjWFf6ssY: list index out of range\n",
      "Error fetching details for video aHPKWjTmDEU: list index out of range\n",
      "Error fetching details for video yVaMtCi9Xw0: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 84/101 [02:17<00:19,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video yVaMtCi9Xw0: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 90/101 [02:22<00:07,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video prcK6Jt9STQ: list index out of range\n",
      "Error fetching details for video LCaxzn0geyQ: list index out of range\n",
      "Error fetching details for video 7Z0qOH9zqoU: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [02:43<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching details for video 0uocETPj4Jx4: list index out of range\n",
      "✅ Scraping complete. Data saved to 'clickbait_extra_transcripts.json' and 'clickbait_extra_transcripts.pkl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import (\n",
    "    TranscriptsDisabled, VideoUnavailable, NoTranscriptFound\n",
    ")\n",
    "from googleapiclient.discovery import build\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set up the YouTube API client (you need a valid API key)\n",
    "API_KEY = 'AIzaSyDeNpVV0yNsa2Th1AEvm8iBFGzZgphnYfY'  # Replace with your API key\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# Load the CSV containing new clickbait video IDs\n",
    "df = pd.read_csv(\"clickbait.csv\")\n",
    "\n",
    "# Standardize the column name for consistency\n",
    "df.rename(columns={\"ID\": \"video_id\"}, inplace=True)\n",
    "\n",
    "# Add a 'transcript' column if it's not already there\n",
    "if 'transcript' not in df.columns:\n",
    "    df['transcript'] = None\n",
    "\n",
    "# Save results to a separate file from the original dataset\n",
    "json_filename = \"clickbait_extra_transcripts.json\"\n",
    "\n",
    "# Function to fetch video details using YouTube API\n",
    "def get_video_details(video_id):\n",
    "    try:\n",
    "        # Retrieve video details using YouTube API\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Extract relevant video details\n",
    "        video_details = response['items'][0]\n",
    "        snippet = video_details['snippet']\n",
    "        statistics = video_details['statistics']\n",
    "\n",
    "        channel_id = snippet['channelId']\n",
    "        channel_name = snippet['channelTitle']\n",
    "        channel_subscribers = get_channel_subscribers(channel_id)\n",
    "        channel_videos = get_channel_videos(channel_id)\n",
    "        channel_views = get_channel_views(channel_id)\n",
    "\n",
    "        video_comments = statistics.get('commentCount', 0)\n",
    "        video_dislikes = statistics.get('dislikeCount', 0)\n",
    "        video_likes = statistics.get('likeCount', 0)\n",
    "        video_views = statistics.get('viewCount', 0)\n",
    "        video_title = snippet['title']\n",
    "\n",
    "        return {\n",
    "            'channel_id': channel_id,\n",
    "            'channel_name': channel_name,\n",
    "            'channel_subscribers': channel_subscribers,\n",
    "            'channel_videos': channel_videos,\n",
    "            'channel_views': channel_views,\n",
    "            'video_comments': video_comments,\n",
    "            'video_dislikes': video_dislikes,\n",
    "            'video_likes': video_likes,\n",
    "            'video_views': video_views,\n",
    "            'video_id': video_id,\n",
    "            'video_title': video_title\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for video {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch channel details like subscribers, videos, and views\n",
    "def get_channel_subscribers(channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"statistics\",\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response['items'][0]['statistics'].get('subscriberCount', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching channel subscribers for {channel_id}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_channel_videos(channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return len(response['items'][0]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching channel videos for {channel_id}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_channel_views(channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"statistics\",\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response['items'][0]['statistics'].get('viewCount', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching channel views for {channel_id}: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Function to fetch transcript with error handling\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return \" \".join([entry['text'] for entry in transcript])\n",
    "    except (TranscriptsDisabled, VideoUnavailable, NoTranscriptFound):\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Filter for videos that haven't been processed yet\n",
    "unscraped_videos = df[df['transcript'].isna()]\n",
    "print(f\"Transcript scraping for {len(unscraped_videos)} videos.\")\n",
    "\n",
    "# Track previously saved video IDs to avoid duplication\n",
    "saved_video_ids = set()\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                saved_video_ids.add(entry[\"video_id\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "# Scrape transcripts and save all information incrementally\n",
    "with open(json_filename, \"a\") as json_file:\n",
    "    for i, row in tqdm(unscraped_videos.iterrows(), total=len(unscraped_videos)):\n",
    "        video_id = row['video_id']\n",
    "\n",
    "        # Skip videos that have already been saved\n",
    "        if video_id in saved_video_ids:\n",
    "            continue\n",
    "\n",
    "        # Get all video details (including transcript)\n",
    "        video_details = get_video_details(video_id)\n",
    "        if not video_details:\n",
    "            continue\n",
    "\n",
    "        # Get the transcript\n",
    "        transcript = get_transcript(video_id)\n",
    "        video_details['transcript'] = transcript\n",
    "\n",
    "        # Save to JSON file\n",
    "        row_dict = {**row.to_dict(), **video_details}\n",
    "        json_file.write(json.dumps(row_dict) + \"\\n\")\n",
    "        json_file.flush()\n",
    "\n",
    "        # Wait to avoid rate-limiting by YouTube\n",
    "        time.sleep(1)\n",
    "\n",
    "# Save final DataFrame as a backup\n",
    "df.to_pickle(\"clickbait_extra_transcripts.pkl\")\n",
    "\n",
    "print(\"✅ Scraping complete. Data saved to 'clickbait_extra_transcripts.json' and 'clickbait_extra_transcripts.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
